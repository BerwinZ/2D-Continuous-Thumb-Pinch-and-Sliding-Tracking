{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models\n",
    "1. Use 20 features and 4 labels from features.csv\n",
    "2. Try different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 2\n",
    "processed_folder = r\".\\ProcessedData\\Dataset_Step=\" + str(step)\n",
    "model_folder = processed_folder + r\"\\models\"\n",
    "features_path = processed_folder + r\"\\features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib \n",
    "import pickle\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, BaggingRegressor, \\\n",
    "BaggingRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor, \\\n",
    "VotingRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from IPython.display import clear_output\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FingerType(Enum):\n",
    "    Thumb = 0\n",
    "    Index = 1\n",
    "\n",
    "finger_type = FingerType.Thumb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape\n",
      "X: (465470, 20)  Y: (465470, 2)\n",
      "Train dataset shape\n",
      "X: (325829, 20)  Y: (325829, 2)\n",
      "Test dataset shape\n",
      "X: (139641, 20)  Y: (139641, 2)\n"
     ]
    }
   ],
   "source": [
    "features_pd = pd.read_csv(features_path)\n",
    "X = features_pd.iloc[:, 0: 20].to_numpy()\n",
    "if finger_type == FingerType.Thumb:\n",
    "    Y =  features_pd.iloc[:, 20: 22].to_numpy()\n",
    "elif finger_type == FingerType.Index:\n",
    "    Y =  features_pd.iloc[:, 22: 24].to_numpy()\n",
    "\n",
    "print(\"Original dataset shape\")\n",
    "print(\"X:\", X.shape, \" Y:\", Y.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "print(\"Train dataset shape\")\n",
    "print(\"X:\", X_train.shape, \" Y:\", Y_train.shape)\n",
    "print(\"Test dataset shape\")\n",
    "print(\"X:\", X_test.shape, \" Y:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare the regression model pipeline\n",
    "### Use multi output regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_joint_model(single_model):\n",
    "    model = MultiOutputRegressor(single_model)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "\n",
    "    score_train = model.score(X_train, Y_train)\n",
    "    score = model.score(X_test, Y_test)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('Score of train', round(score_train * 100, 1), \"%\")\n",
    "    print('Score of test', round(score * 100, 1), \"%\")\n",
    "    \n",
    "    model_path = model_folder + \"\\\\\" +  \\\n",
    "                    str(round(score, 3)).replace('.', '_') + r\"_\" +  \\\n",
    "                    str(model.get_params()['estimator']).split('(')[0] + \\\n",
    "                    '.joblib'\n",
    "    joblib.dump(model, model_path)\n",
    "    print(\"Save model file\", model_path)\n",
    "    \n",
    "    return model, model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use single output regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_models(single_model):\n",
    "    models = []\n",
    "    file_label = ['x', 'y']\n",
    "    scores = []\n",
    "    file_names = []\n",
    "    for i in range(2):\n",
    "        model = deepcopy(single_model)    \n",
    "        model.fit(X_train, Y_train[:, i])\n",
    "    \n",
    "        models.append(model)\n",
    "        \n",
    "        score_train = model.score(X_train, Y_train[:, i])\n",
    "        score_test  = model.score(X_test, Y_test[:, i])\n",
    "        \n",
    "        single_score = {'train': score_train, 'test': score_test}\n",
    "        scores.append(single_score)\n",
    "        \n",
    "        model_path = model_folder + r'\\\\' +  \\\n",
    "                        str(round(score_test, 3)).replace('.', '_') + r'_' +  \\\n",
    "                        str(type(single_model)).split('.')[-1].split('\\'')[0] + r'_' + \\\n",
    "                        file_label[i] + '.joblib'\n",
    "        joblib.dump(model, model_path)\n",
    "        file_names.append(model_path)\n",
    "        \n",
    "    clear_output(wait=True)\n",
    "    for i in range(2):\n",
    "        print(file_label[i])\n",
    "        print('Score of train', round(scores[i]['train'] * 100, 1), \"%\")\n",
    "        print('Score of test',  round(scores[i]['test']  * 100, 1), \"%\")\n",
    "        print(\"Save model file\", file_names[i])\n",
    "    \n",
    "    return models, file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_model = SVR(kernel='linear', C=1.0, epsilon=0.2, max_iter=10000)\n",
    "# single_model = SVR(kernel='poly', C=1.0, epsilon=0.2, max_iter=10000)\n",
    "# single_model = SVR(kernel='sigmoid', C=1.0, epsilon=0.2, tol=0.1)\n",
    "# single_model = LogisticRegression(random_state=0)\n",
    "\n",
    "single_model = RandomForestRegressor(n_estimators=10, max_depth=None, \n",
    "                                     min_samples_split=15, min_samples_leaf=15,\n",
    "                                     verbose=3)\n",
    "# single_model = RandomForestRegressor(n_estimators=60, max_depth=None, criterion='mae',\n",
    "#                                      min_samples_split=15, min_samples_leaf=15, verbose=1)\n",
    "\n",
    "\n",
    "# single_model = LinearRegression()\n",
    "\n",
    "# single_model = AdaBoostRegressor(random_state=0, n_estimators=100, loss='square')\n",
    "# single_model = BaggingRegressor(base_estimator=SVR(), n_estimators=10, random_state=0)\n",
    "\n",
    "# ** single_model = GradientBoostingRegressor(n_estimators=10000)\n",
    "# ** single_model = HistGradientBoostingRegressor(max_iter=10000)\n",
    "\n",
    "# r1 = RandomForestRegressor(max_depth=None, random_state=None)\n",
    "# r2 = GradientBoostingRegressor(n_estimators=10000)\n",
    "# r3 = HistGradientBoostingRegressor(max_iter=10000)\n",
    "# ** single_model = VotingRegressor([('RF', r1), ('GB', r2), ('HGB', r3)])\n",
    "\n",
    "# LR1 = LinearRegression()\n",
    "# LR2 = LinearRegression()\n",
    "# LR3 = LinearRegression()\n",
    "# single_model = VotingRegressor([('LR1', r1), ('LR2', r2), ('LR3', r3)])\n",
    "\n",
    "# ** single_model = lgb.LGBMRegressor(boosting_type='dart', num_leaves=10, n_estimators=100)\n",
    "\n",
    "# single_model = MLPRegressor()\n",
    "\n",
    "# kernel = DotProduct() + WhiteKernel()\n",
    "# single_model = GaussianProcessRegressor(kernel=kernel, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of train 92.4 %\n",
      "Score of test 90.6 %\n",
      "Save model file .\\ProcessedData\\Dataset_Step=2\\models\\0_906_RandomForestRegressor.joblib\n"
     ]
    }
   ],
   "source": [
    "model, model_path = generate_joint_model(single_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "Score of train 90.9 %\n",
      "Score of test 88.9 %\n",
      "Save model file .\\ProcessedData\\Dataset_Step=2\\models\\\\0_889_RandomForestRegressor_x.joblib\n",
      "y\n",
      "Score of train 94.0 %\n",
      "Score of test 92.4 %\n",
      "Save model file .\\ProcessedData\\Dataset_Step=2\\models\\\\0_924_RandomForestRegressor_y.joblib\n"
     ]
    }
   ],
   "source": [
    "models, model_paths = generate_single_models(single_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load model from disk and test on other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape\n",
      "X: (54268, 20)  Y: (54268, 2)\n"
     ]
    }
   ],
   "source": [
    "step = 3\n",
    "features_pd = pd.read_csv(r\".\\ProcessedData\\Dataset_Step=\" + str(step) + r\"\\features.csv\")\n",
    "X_a = features_pd.iloc[:, 0: 20].to_numpy()\n",
    "if finger_type == FingerType.Thumb:\n",
    "    Y_a =  features_pd.iloc[:, 20: 22].to_numpy()\n",
    "elif finger_type == FingerType.Index:\n",
    "    Y_a =  features_pd.iloc[:, 22: 24].to_numpy()\n",
    "print(\"Original dataset shape\")\n",
    "print(\"X:\", X_a.shape, \" Y:\", Y_a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r'./ProcessedData/Dataset_Step=3/models/0_89_RandomForestRegressor.joblib'\n",
    "model = joblib.load(model_path)\n",
    "# model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on another dataset 73.1 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "score = model.score(X_a, Y_a)\n",
    "print('Score on another dataset', round(score * 100, 1), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Convert to other format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
